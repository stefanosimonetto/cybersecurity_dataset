{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting trafilatura\n",
      "  Downloading trafilatura-2.0.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\simonettos\\appdata\\roaming\\python\\python311\\site-packages (from trafilatura) (2022.12.7)\n",
      "Collecting charset_normalizer>=3.4.0 (from trafilatura)\n",
      "  Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting courlan>=1.3.2 (from trafilatura)\n",
      "  Downloading courlan-1.3.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting htmldate>=1.9.2 (from trafilatura)\n",
      "  Downloading htmldate-1.9.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting justext>=3.0.1 (from trafilatura)\n",
      "  Downloading jusText-3.0.1-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting lxml>=5.3.0 (from trafilatura)\n",
      "  Downloading lxml-5.3.0-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\simonettos\\appdata\\roaming\\python\\python311\\site-packages (from trafilatura) (1.26.15)\n",
      "Collecting babel>=2.16.0 (from courlan>=1.3.2->trafilatura)\n",
      "  Downloading babel-2.16.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tld>=0.13 (from courlan>=1.3.2->trafilatura)\n",
      "  Downloading tld-0.13-py2.py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting dateparser>=1.1.2 (from htmldate>=1.9.2->trafilatura)\n",
      "  Downloading dateparser-1.2.0-py2.py3-none-any.whl.metadata (28 kB)\n",
      "Collecting python-dateutil>=2.9.0.post0 (from htmldate>=1.9.2->trafilatura)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: pytz in c:\\users\\simonettos\\appdata\\roaming\\python\\python311\\site-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2023.3)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in c:\\users\\simonettos\\appdata\\roaming\\python\\python311\\site-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2023.6.3)\n",
      "Collecting tzlocal (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura)\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting lxml-html-clean (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura)\n",
      "  Downloading lxml_html_clean-0.4.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\simonettos\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.9.0.post0->htmldate>=1.9.2->trafilatura) (1.16.0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\simonettos\\appdata\\roaming\\python\\python311\\site-packages (from tzlocal->dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2023.3)\n",
      "Downloading trafilatura-2.0.0-py3-none-any.whl (132 kB)\n",
      "   ---------------------------------------- 0.0/132.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 132.6/132.6 kB 8.2 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 101.8/101.8 kB 6.1 MB/s eta 0:00:00\n",
      "Downloading courlan-1.3.2-py3-none-any.whl (33 kB)\n",
      "Downloading htmldate-1.9.2-py3-none-any.whl (31 kB)\n",
      "Downloading jusText-3.0.1-py2.py3-none-any.whl (837 kB)\n",
      "   ---------------------------------------- 0.0/837.8 kB ? eta -:--:--\n",
      "   -------------------- ------------------ 450.6/837.8 kB 13.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 837.8/837.8 kB 10.6 MB/s eta 0:00:00\n",
      "Downloading lxml-5.3.0-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.7/3.8 MB 14.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.6/3.8 MB 16.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.7/3.8 MB 18.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 22.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 20.2 MB/s eta 0:00:00\n",
      "Downloading babel-2.16.0-py3-none-any.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.3/9.6 MB 42.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.1/9.6 MB 27.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.4/9.6 MB 27.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.3/9.6 MB 24.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.2/9.6 MB 23.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.2/9.6 MB 23.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.1/9.6 MB 22.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.1/9.6 MB 22.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.1/9.6 MB 22.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.6/9.6 MB 22.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 21.1 MB/s eta 0:00:00\n",
      "Downloading dateparser-1.2.0-py2.py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/295.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 295.0/295.0 kB 19.0 MB/s eta 0:00:00\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading tld-0.13-py2.py3-none-any.whl (263 kB)\n",
      "   ---------------------------------------- 0.0/263.8 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 122.9/263.8 kB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 256.0/263.8 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 263.8/263.8 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading lxml_html_clean-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: tzlocal, tld, python-dateutil, lxml, charset_normalizer, babel, lxml-html-clean, dateparser, courlan, htmldate, justext, trafilatura\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.9.3\n",
      "    Uninstalling lxml-4.9.3:\n",
      "      Successfully uninstalled lxml-4.9.3\n",
      "  Attempting uninstall: charset_normalizer\n",
      "    Found existing installation: charset-normalizer 3.1.0\n",
      "    Uninstalling charset-normalizer-3.1.0:\n",
      "      Successfully uninstalled charset-normalizer-3.1.0\n",
      "  Attempting uninstall: babel\n",
      "    Found existing installation: Babel 2.13.1\n",
      "    Uninstalling Babel-2.13.1:\n",
      "      Successfully uninstalled Babel-2.13.1\n",
      "Successfully installed babel-2.16.0 charset_normalizer-3.4.0 courlan-1.3.2 dateparser-1.2.0 htmldate-1.9.2 justext-3.0.1 lxml-5.3.0 lxml-html-clean-0.4.1 python-dateutil-2.9.0.post0 tld-0.13 trafilatura-2.0.0 tzlocal-5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\program files\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\SimonettoS\\AppData\\Roaming\\Python\\Python311\\site-packages\\~harset_normalizer'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2023.12.0 requires fsspec==2023.12.0, but you have fsspec 2023.10.0 which is incompatible.\n",
      "pinecone-datasets 0.5.0rc11 requires pyarrow<12.0.0,>=11.0.0, but you have pyarrow 15.0.0 which is incompatible.\n",
      "pinecone-datasets 0.5.0rc11 requires pydantic<2.0.0,>=1.10.5, but you have pydantic 2.10.2 which is incompatible.\n",
      "s3fs 2023.12.0 requires fsspec==2023.12.0, but you have fsspec 2023.10.0 which is incompatible.\n",
      "stix2-validator 3.1.4 requires jsonschema[format-nongpl]<4.18.0,>=4.6.0, but you have jsonschema 4.20.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install trafilatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:   1%|‚ñè         | 1989/151806 [02:18<2:53:36, 14.38it/s]\n"
     ]
    }
   ],
   "source": [
    "import trafilatura\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Read URLs from the file\n",
    "urls = open('sources/urls_web.txt').read().split()\n",
    "\n",
    "# Function to process a single URL\n",
    "def process_url(url):\n",
    "    try:\n",
    "        content = trafilatura.fetch_url(url)\n",
    "        if content:\n",
    "            extracted = trafilatura.extract(content, output_format='json', include_comments=False)\n",
    "            if extracted:\n",
    "                extracted_json = json.loads(extracted)  # Parse the JSON string\n",
    "                text = extracted_json.get(\"text\", \"\")  # Get only the \"text\" field\n",
    "                return {\"url\": url, \"Text\": text}\n",
    "    except Exception as e:\n",
    "        return {\"url\": url, \"Text\": f\"Error: {str(e)}\"}\n",
    "\n",
    "    return {\"url\": url, \"Text\": \"\"}  # Default if nothing was fetched or extracted\n",
    "\n",
    "# Use ThreadPoolExecutor for multithreading\n",
    "results = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    # Submit all URLs to the executor\n",
    "    futures = {executor.submit(process_url, url): url for url in urls}\n",
    "\n",
    "    # Use tqdm to display progress\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing URLs\"):\n",
    "        results.append(future.result())\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open('output.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Data has been saved to output.json.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
